{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9fcba59",
   "metadata": {},
   "source": [
    "# Contact Database Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7105c3",
   "metadata": {},
   "source": [
    "This project presents an end-to-end data analytics research based on a large-scale dataset exported directly from HubSpot, containing over 70,000 records. The dataset represents real-world CRM data and captures multiple dimensions of customer, company, deal (revenue), and traffic attribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b982a2f3",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb23657c",
   "metadata": {},
   "source": [
    "Importing required libraries for data loading, inspection and initial cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c21e7451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data manipulation and analysis\n",
    "import numpy as np # numerical operations\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "import warnings # to handle warnings (e.g., deprecation warnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08dedfb",
   "metadata": {},
   "source": [
    "Importing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3318bd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Full Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Create Date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Email",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Industry",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Website URL",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Country/Region",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Annual Revenue",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Lifecycle Stage",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Original Source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Original Source Drill-Down 1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Deal Stage",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Closed amount",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "95a974da-7437-4de4-a1c1-28edb168aa7b",
       "rows": [
        [
         "0",
         "Darren Lindsay",
         "21/10/2022 11:06",
         "darren@agmchilleddistribution.co.uk",
         "Logistics",
         "agmchilleddistribution.co.uk",
         "United Kingdom",
         "(No value)",
         "Opportunity",
         "Paid Search",
         "cold stores uk",
         "(No value)",
         "(No value)"
        ],
        [
         "1",
         "Grady Broadhurst",
         "18/10/2022 10:58",
         "gradyb@hotmail.co.uk",
         "(No value)",
         "(No value)",
         "United Kingdom",
         "(No value)",
         "Lead",
         "Paid Search",
         "blast freezer uk",
         "(No value)",
         "(No value)"
        ],
        [
         "2",
         "Graham hall",
         "17/10/2022 14:09",
         "info@hallsofhazlemere.com",
         "(No value)",
         "hallsofhazlemere.com",
         "England",
         "(No value)",
         "Lead",
         "Paid Search",
         "refrigerated containers",
         "(No value)",
         "(No value)"
        ],
        [
         "3",
         "Kate Sampson",
         "25/10/2022 15:09",
         "kate@copas.co.uk",
         "Meat",
         "copas.co.uk",
         "(No value)",
         "10000000",
         "Lead",
         "Direct Traffic",
         "www.crscoldstorage.co.uk/refrigeration/refrigerated-containers/berkshire.html",
         "(No value)",
         "(No value)"
        ],
        [
         "4",
         "martin rowland",
         "26/10/2022 09:18",
         "martinrowland30@gmail.com",
         "Hospitality",
         "(No value)",
         "United Kingdom",
         "(No value)",
         "Customer",
         "Paid Search",
         "cold stores uk",
         "Closed Won (Salesforce - Opportunity)",
         "9320"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full Name</th>\n",
       "      <th>Create Date</th>\n",
       "      <th>Email</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Website URL</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Annual Revenue</th>\n",
       "      <th>Lifecycle Stage</th>\n",
       "      <th>Original Source</th>\n",
       "      <th>Original Source Drill-Down 1</th>\n",
       "      <th>Deal Stage</th>\n",
       "      <th>Closed amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Darren Lindsay</td>\n",
       "      <td>21/10/2022 11:06</td>\n",
       "      <td>darren@agmchilleddistribution.co.uk</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>agmchilleddistribution.co.uk</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>(No value)</td>\n",
       "      <td>Opportunity</td>\n",
       "      <td>Paid Search</td>\n",
       "      <td>cold stores uk</td>\n",
       "      <td>(No value)</td>\n",
       "      <td>(No value)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grady Broadhurst</td>\n",
       "      <td>18/10/2022 10:58</td>\n",
       "      <td>gradyb@hotmail.co.uk</td>\n",
       "      <td>(No value)</td>\n",
       "      <td>(No value)</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>(No value)</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Paid Search</td>\n",
       "      <td>blast freezer uk</td>\n",
       "      <td>(No value)</td>\n",
       "      <td>(No value)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Graham hall</td>\n",
       "      <td>17/10/2022 14:09</td>\n",
       "      <td>info@hallsofhazlemere.com</td>\n",
       "      <td>(No value)</td>\n",
       "      <td>hallsofhazlemere.com</td>\n",
       "      <td>England</td>\n",
       "      <td>(No value)</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Paid Search</td>\n",
       "      <td>refrigerated containers</td>\n",
       "      <td>(No value)</td>\n",
       "      <td>(No value)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kate Sampson</td>\n",
       "      <td>25/10/2022 15:09</td>\n",
       "      <td>kate@copas.co.uk</td>\n",
       "      <td>Meat</td>\n",
       "      <td>copas.co.uk</td>\n",
       "      <td>(No value)</td>\n",
       "      <td>10000000</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Direct Traffic</td>\n",
       "      <td>www.crscoldstorage.co.uk/refrigeration/refrige...</td>\n",
       "      <td>(No value)</td>\n",
       "      <td>(No value)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>martin rowland</td>\n",
       "      <td>26/10/2022 09:18</td>\n",
       "      <td>martinrowland30@gmail.com</td>\n",
       "      <td>Hospitality</td>\n",
       "      <td>(No value)</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>(No value)</td>\n",
       "      <td>Customer</td>\n",
       "      <td>Paid Search</td>\n",
       "      <td>cold stores uk</td>\n",
       "      <td>Closed Won (Salesforce - Opportunity)</td>\n",
       "      <td>9320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Full Name       Create Date                                Email  \\\n",
       "0    Darren Lindsay  21/10/2022 11:06  darren@agmchilleddistribution.co.uk   \n",
       "1  Grady Broadhurst  18/10/2022 10:58                 gradyb@hotmail.co.uk   \n",
       "2       Graham hall  17/10/2022 14:09            info@hallsofhazlemere.com   \n",
       "3      Kate Sampson  25/10/2022 15:09                     kate@copas.co.uk   \n",
       "4    martin rowland  26/10/2022 09:18            martinrowland30@gmail.com   \n",
       "\n",
       "      Industry                   Website URL  Country/Region Annual Revenue  \\\n",
       "0    Logistics  agmchilleddistribution.co.uk  United Kingdom     (No value)   \n",
       "1   (No value)                    (No value)  United Kingdom     (No value)   \n",
       "2   (No value)          hallsofhazlemere.com         England     (No value)   \n",
       "3         Meat                   copas.co.uk      (No value)       10000000   \n",
       "4  Hospitality                    (No value)  United Kingdom     (No value)   \n",
       "\n",
       "  Lifecycle Stage Original Source  \\\n",
       "0     Opportunity     Paid Search   \n",
       "1            Lead     Paid Search   \n",
       "2            Lead     Paid Search   \n",
       "3            Lead  Direct Traffic   \n",
       "4        Customer     Paid Search   \n",
       "\n",
       "                        Original Source Drill-Down 1  \\\n",
       "0                                     cold stores uk   \n",
       "1                                   blast freezer uk   \n",
       "2                            refrigerated containers   \n",
       "3  www.crscoldstorage.co.uk/refrigeration/refrige...   \n",
       "4                                     cold stores uk   \n",
       "\n",
       "                              Deal Stage Closed amount  \n",
       "0                             (No value)    (No value)  \n",
       "1                             (No value)    (No value)  \n",
       "2                             (No value)    (No value)  \n",
       "3                             (No value)    (No value)  \n",
       "4  Closed Won (Salesforce - Opportunity)          9320  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_path = \"data/multi-dimensional-contact-segme.csv\"\n",
    "\n",
    "df = pd.read_csv(raw_path) # Inspecting the dataset\n",
    "df.head() # Displays the first few rows of the dataset\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b61262c",
   "metadata": {},
   "source": [
    "## Managing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6ffbff46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72198 entries, 0 to 72197\n",
      "Data columns (total 12 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   Full Name                     72198 non-null  object\n",
      " 1   Create Date                   72198 non-null  object\n",
      " 2   Email                         72198 non-null  object\n",
      " 3   Industry                      72198 non-null  object\n",
      " 4   Website URL                   72198 non-null  object\n",
      " 5   Country/Region                72187 non-null  object\n",
      " 6   Annual Revenue                72198 non-null  object\n",
      " 7   Lifecycle Stage               72198 non-null  object\n",
      " 8   Original Source               72198 non-null  object\n",
      " 9   Original Source Drill-Down 1  72198 non-null  object\n",
      " 10  Deal Stage                    72198 non-null  object\n",
      " 11  Closed amount                 72198 non-null  object\n",
      "dtypes: object(12)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Inspecting missing values\n",
    "\n",
    "df.info() # Shows column names, non-null counts, and inferred data types.\n",
    "# Reference: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html\n",
    "\n",
    "df.isna().sum() # Counts true missing values (NaN) in each column.\n",
    "# Reference: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html\n",
    "\n",
    "np.sum(df == \"(No value)\") # Counts custom missing value indicators in each column.\n",
    "# Reference: https://numpy.org/doc/stable/reference/generated/numpy.sum.html\n",
    "\n",
    "np.sum(df == \"(No value)\", axis=0) # Counts custom missing value indicators.\n",
    "# Using `axis=0 to sum over rows for each column.\n",
    "# Reference: https://numpy.org/doc/stable/reference/generated/numpy.sum.html\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") # Suppresses warnings for cleaner output\n",
    "# Reference: https://docs.python.org/3/library/warnings.html#warnings.filterwarnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8baf761",
   "metadata": {},
   "source": [
    "Before cleaning the dataset, it is necessary to understand where the missing or incomplete values occur.<br>\n",
    "HubSpot exports often contain two types of missing data:\n",
    "- True missing values (NaN), recognised automatically by pandas.\n",
    "- Placeholder strings such as \"(No value)\", which are not treated as missing values by pandas but still represent incomplete data.<br>\n",
    "This step profiles both kinds. No rows will be removed; instead, missing fields will be handled in a way that preserves as much useful information as possible.\n",
    "\n",
    "NumPy is used for the boolean-array summation because it provides a clear and efficient way to count True/False values across the dataset.\n",
    "\n",
    "*Handling Warnings:*<br>\n",
    "Python libraries such as pandas and NumPy often generate non-critical warnings during data analysis (e.g., FutureWarning or DeprecationWarning). These warnings do not indicate errors and do not affect the correctness of the analysis, but they can clutter the notebook output and make results harder to interpret. The warnings module is used here to suppress non-essential warnings, improving readability while still allowing real errors to appear.\n",
    "\n",
    "**ðŸ“š References:**<br>\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html\n",
    "- https://numpy.org/doc/stable/reference/generated/numpy.sum.html\n",
    "- https://numpy.org/doc/stable/reference/generated/numpy.sum.html\n",
    "- https://stackoverflow.com/questions/27261015/boolean-in-a-numpy-sum\n",
    "- https://numpy.org/devdocs/reference/generated/numpy.sum.html\n",
    "- https://docs.python.org/3/library/warnings.html#warnings.filterwarnings\n",
    "- https://docs.python.org/3/library/warnings.html\n",
    "- https://stackoverflow.com/questions/3920502/how-to-suppress-a-third-party-warning-using-warnings-filterwarnings\n",
    "- https://www.geeksforgeeks.org/python/how-to-disable-python-warnings/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2434297b",
   "metadata": {},
   "source": [
    "## Data Cleaning - part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905dbcc8",
   "metadata": {},
   "source": [
    "Before cleaning the dataset, it is essential to quantify how many \"(No value)\" placeholders appear in each column.<br>\n",
    "HubSpot uses \"(No value)\" to represent missing or unavailable data across every field, not just numeric columns.\n",
    "\n",
    "Pandas does not recognise \"(No value)\" as a missing value (`NaN`), so knowing the frequency of this placeholder is necessary to:\n",
    "- understand how complete data is\n",
    "- prepare an appropriate cleaning strategy\n",
    "- prevent errors during later type conversions (numeric or datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fe795e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "20d7709a-5e4e-4f1d-addd-5f1fc0573835",
       "rows": [
        [
         "Full Name",
         "72192"
        ],
        [
         "Create Date",
         "0"
        ],
        [
         "Email",
         "11"
        ],
        [
         "Industry",
         "18103"
        ],
        [
         "Website URL",
         "22306"
        ],
        [
         "Country/Region",
         "9913"
        ],
        [
         "Annual Revenue",
         "35597"
        ],
        [
         "Lifecycle Stage",
         "7214"
        ],
        [
         "Original Source",
         "0"
        ],
        [
         "Original Source Drill-Down 1",
         "0"
        ],
        [
         "Deal Stage",
         "68058"
        ],
        [
         "Closed amount",
         "68060"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 12
       }
      },
      "text/plain": [
       "Full Name                       72192\n",
       "Create Date                         0\n",
       "Email                              11\n",
       "Industry                        18103\n",
       "Website URL                     22306\n",
       "Country/Region                   9913\n",
       "Annual Revenue                  35597\n",
       "Lifecycle Stage                  7214\n",
       "Original Source                     0\n",
       "Original Source Drill-Down 1        0\n",
       "Deal Stage                      68058\n",
       "Closed amount                   68060\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting how many times the placeholder \"(No value)\" appears in each column.\n",
    "(df == \"(No value)\").sum()\n",
    "# This expression uses boolean comparison to create a True/False dataframe.\n",
    "# True indicates a cell that exactly matches \"(No value)\".\n",
    "# The .sum() operation counts True values per column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c054d019",
   "metadata": {},
   "source": [
    "`df == \"(No value)\"` compares every cell in the dataframe against the string \"(No value)\".<br>\n",
    "`.sum()`here pandas treats True as 1 and False as 0.\n",
    "\n",
    "The output gives a better insight:<br>\n",
    "- A lot of missing data which varies between columns.\n",
    "- Numeric fields (Annual revenue and Closed amount) require different approach\n",
    "- Fields such as Email, Original source and Original source drill-down 1 are complete or almost complete and give us very reliable insight.\n",
    "\n",
    "**ðŸ“š References:**<br>\n",
    "- https://www.geeksforgeeks.org/pandas/boolean-indexing-in-pandas/\n",
    "- https://pandas.pydata.org/docs/user_guide/indexing.html#boolean-indexing\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html\n",
    "- https://www.w3schools.com/python/pandas/ref_df_sum.asp#:~:text=The%20sum()%20method%20adds,the%20sum%20of%20each%20row.\n",
    "- https://stackoverflow.com/questions/38733477/whats-the-best-way-to-sum-all-values-in-a-pandas-dataframe\n",
    "- https://towardsdatascience.com/3-approaches-to-find-missing-values-ff656eba6902/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c388b07",
   "metadata": {},
   "source": [
    "## Data Cleaning - part 2 (per column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daff6beb",
   "metadata": {},
   "source": [
    "### Approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982e2a84",
   "metadata": {},
   "source": [
    "The HubSpot dataset is inconsistent so each column needs to be addressed individually.\n",
    "\n",
    "1. **Full Name** - this column contains \"(No value)\" in almost all rows. \"(No value)\" will be replaced with `NaN`. Also, this column is too incomplete for further analysis.\n",
    "\n",
    "2. **Create Date** - no missing values in this column, which is a good thing. This column needs to be converted to datetime for time-based analysis.\n",
    "\n",
    "3. **Email** - contains only 11 \"(No Value\") spots. Because the Website URL column contains over 22,000 missing entries, the Email column becomes the most reliable source for extracting domain-level company information (for example: `ian.bartlett@aldi.co.uk` â†’ `aldi.co.uk`). <br>\n",
    "Also, corporate emails (such as `@dornangroup.com`) indicate larger companies, while personal emails (`@gmail.com`, etc.) represent sole traders and smaller businesses. This will help for further segmentation.\n",
    "\n",
    "4. **Industry** - has 18,103 missing values but still enough data for segmentation.\n",
    "\n",
    "5. **Website URL** - 22,306 missing values, but this can be supplemented as explained in the Email section.\n",
    "\n",
    "6. **Country/Region** - 9,913 missing values but still solid amount of data. The Email field becomes the most reliable secondary source for finding geographic information (for example: co.uk â†’ United Kindom, .ie â†’ Ireland and so on).\n",
    "\n",
    "7. **Annual Revenue** - even though this field contains 35,597 missing entries, the values that are present still provide a lot of value. Many rows include very large revenue figures (e.g., Â£10 million, Â£250 million, etc.), which indicate that a subset of the contacts represents high-value corporate entities. Existing values need to be converted from string to numeric.\n",
    "\n",
    "8. **Lifecycle stage** - 7,214 missing values, still good for segmentation.\n",
    "\n",
    "9. **Original Source** - no missing values, which is great.\n",
    "\n",
    "10. **Original Source Drill-Down 1** - this column shows further drill down of the Original Source (for example: original source is offline, but drill-down shows it is a Salesforce import OR original source shows Paid search but the Drill down column shows the exact keywords). This column enhances categories from the Original Source.<br>\n",
    "Analysis options:\n",
    "- Attribution analysis - identifying which keywords, campaigns, or Salesforce import types generate the most contacts or conversions.\n",
    "- Keyword-level segmentation - extracting search terms to detect user intent (where applicable).\n",
    "- CRM integration insights - shows how many contacts and/or won deals come from Salesforce database import.\n",
    "- Further drill-down possible based on the above findings.\n",
    "\n",
    "11. **Deal Stage** - contains 68,058 non-values, which is expected because most contacts in a CRM system never enter a sales pipeline. However, the remaining values (such as 'Closed Won (Salesforce - Opportunity)' or 'Quote Given (Salesforce - Opportunity)') can provide useful information for analysis and sales funnel insights.\n",
    "\n",
    "12. **Closed amount** - requires conversion of numeric values to be used in further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf4940f",
   "metadata": {},
   "source": [
    "### Replacement of \"(No value)\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "91d35554",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(\"(No value)\", np.nan) # Replacing \"(No value)\" with actual NaN for consistency in missing data representation.\n",
    "# Reference: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8039478d",
   "metadata": {},
   "source": [
    "The above code replaces \"(No value)\" across the dataset.\n",
    "\n",
    "**ðŸ“š References:**<br>\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html\n",
    "- https://stackoverflow.com/questions/29247712/how-to-replace-a-value-in-pandas-with-nan\n",
    "- https://www.geeksforgeeks.org/data-analysis/working-with-missing-data-in-pandas/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a644400",
   "metadata": {},
   "source": [
    "### Conversion from string to numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fd790f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annual Revenue: converting to numeric, coercing errors to NaN\n",
    "\n",
    "df['Annual Revenue'] = pd.to_numeric(df['Annual Revenue'], errors='coerce')\n",
    "# pd.to_numeric converts string values into numeric dtype.\n",
    "# errors='coerce' ensures that any invalid or non-numeric values are converted to NaN.\n",
    "\n",
    "# Closed amount: same as above\n",
    "df['Closed amount'] = pd.to_numeric(df['Closed amount'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f2715",
   "metadata": {},
   "source": [
    "In the above step, the 'Annual Revenue' and 'Closed amount' colums were converted from text (string) format into numerical values. Because both columns contain a mix of numeric strings and missing values, `errors='coerce'` was used â†’ this instructs pandas to convert strings into real numbers and to replace missing values with NaN.\n",
    "\n",
    "**ðŸ“š References:**<br>\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html\n",
    "- https://www.geeksforgeeks.org/python/python-pandas-to_numeric-method/\n",
    "- https://stackoverflow.com/questions/57286501/why-pd-to-numeric-errors-is-equivalent-to-errors-coerce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2926b4",
   "metadata": {},
   "source": [
    "### Conversion to datetime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5257d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Date: converting to datetime, coercing errors to NaT\n",
    "\n",
    "df['Create Date'] = pd.to_datetime(df['Create Date'], errors='coerce')\n",
    "# pd.to_datetime converts string-formatted dates into pandas datetime objects.\n",
    "# errors='coerce' ensures invalid or unrecognized date strings become NaT instead of raising an error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65263eb7",
   "metadata": {},
   "source": [
    "In the above step, the Create Date column was converted from text into a proper datetime format.<br>\n",
    "Converting the column with `pd.to_datetime()` ensures that the dates can be used for time-based analysis such as filtering, grouping by month or year, etc. Using `errors='coerce'` ensures that any invalid date values are converted to `NaT` to prevent errors.\n",
    "\n",
    "**ðŸ“š References:**<br>\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html\n",
    "- https://www.geeksforgeeks.org/pandas/python-pandas-to_datetime/\n",
    "- https://stackoverflow.com/questions/36692861/avoiding-error-from-pd-to-datetime-in-pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf236f2",
   "metadata": {},
   "source": [
    "### Email formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "96d6d269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Email",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "5d893ad7-875c-49e3-9480-cb2872a63b99",
       "rows": [
        [
         "0",
         "darren@agmchilleddistribution.co.uk"
        ],
        [
         "1",
         "gradyb@hotmail.co.uk"
        ],
        [
         "2",
         "info@hallsofhazlemere.com"
        ],
        [
         "3",
         "kate@copas.co.uk"
        ],
        [
         "4",
         "martinrowland30@gmail.com"
        ],
        [
         "5",
         "simon@cakesmiths.com"
        ],
        [
         "6",
         "justin@ravenexpress.co.uk"
        ],
        [
         "7",
         "adam.thomas@greencore.com"
        ],
        [
         "8",
         "allstarprov@optonline.net"
        ],
        [
         "9",
         "gill.lyth@stuartandswan.co.uk"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "0    darren@agmchilleddistribution.co.uk\n",
       "1                   gradyb@hotmail.co.uk\n",
       "2              info@hallsofhazlemere.com\n",
       "3                       kate@copas.co.uk\n",
       "4              martinrowland30@gmail.com\n",
       "5                   simon@cakesmiths.com\n",
       "6              justin@ravenexpress.co.uk\n",
       "7              adam.thomas@greencore.com\n",
       "8              allstarprov@optonline.net\n",
       "9          gill.lyth@stuartandswan.co.uk\n",
       "Name: Email, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Email: standardising formatting by trimming whitespace and converting to lowercase\n",
    "\n",
    "df['Email'] = df['Email'].str.strip()\n",
    "# .str.strip() removes leading and trailing whitespace characters from each string in the column.\n",
    "\n",
    "df['Email'] = df['Email'].str.lower()\n",
    "# .str.lower() converts all characters in the string to lowercase\n",
    "# keeps consistency for domain extraction and comparison\n",
    "\n",
    "df['Email'].head(10)\n",
    "# Displays the first 10 entries of the cleaned 'Email' column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ef26d3",
   "metadata": {},
   "source": [
    "Before extracting information from the Email column, the raw email strings must be cleaned and standardised. This involves converting all email addresses to lowercase and removing any leading or trailing whitespace. These corrections ensure consistent handling of domains, accurate classification of email types, and reliable matching during segmentation.\n",
    "\n",
    "**ðŸ“š References:**<br>\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.Series.str.strip.html\n",
    "- https://www.w3schools.com/python/ref_string_strip.asp\n",
    "- https://www.geeksforgeeks.org/pandas/python-pandas-series-str-strip-lstrip-and-rstrip/\n",
    "- https://stackoverflow.com/questions/40950310/strip-trim-all-strings-of-a-dataframe\n",
    "- https://www.w3schools.com/python/ref_string_lower.asp\n",
    "- https://www.geeksforgeeks.org/python/python-string-lower/\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e40ecf",
   "metadata": {},
   "source": [
    "### Extracting email domains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9f34f038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Email",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Email Domain",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "ed7e1c79-4318-4313-80a9-fcdb3054cbd4",
       "rows": [
        [
         "0",
         "darren@agmchilleddistribution.co.uk",
         "agmchilleddistribution.co.uk"
        ],
        [
         "1",
         "gradyb@hotmail.co.uk",
         "hotmail.co.uk"
        ],
        [
         "2",
         "info@hallsofhazlemere.com",
         "hallsofhazlemere.com"
        ],
        [
         "3",
         "kate@copas.co.uk",
         "copas.co.uk"
        ],
        [
         "4",
         "martinrowland30@gmail.com",
         "gmail.com"
        ],
        [
         "5",
         "simon@cakesmiths.com",
         "cakesmiths.com"
        ],
        [
         "6",
         "justin@ravenexpress.co.uk",
         "ravenexpress.co.uk"
        ],
        [
         "7",
         "adam.thomas@greencore.com",
         "greencore.com"
        ],
        [
         "8",
         "allstarprov@optonline.net",
         "optonline.net"
        ],
        [
         "9",
         "gill.lyth@stuartandswan.co.uk",
         "stuartandswan.co.uk"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Email Domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>darren@agmchilleddistribution.co.uk</td>\n",
       "      <td>agmchilleddistribution.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gradyb@hotmail.co.uk</td>\n",
       "      <td>hotmail.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>info@hallsofhazlemere.com</td>\n",
       "      <td>hallsofhazlemere.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kate@copas.co.uk</td>\n",
       "      <td>copas.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>martinrowland30@gmail.com</td>\n",
       "      <td>gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>simon@cakesmiths.com</td>\n",
       "      <td>cakesmiths.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>justin@ravenexpress.co.uk</td>\n",
       "      <td>ravenexpress.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adam.thomas@greencore.com</td>\n",
       "      <td>greencore.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>allstarprov@optonline.net</td>\n",
       "      <td>optonline.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gill.lyth@stuartandswan.co.uk</td>\n",
       "      <td>stuartandswan.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Email                  Email Domain\n",
       "0  darren@agmchilleddistribution.co.uk  agmchilleddistribution.co.uk\n",
       "1                 gradyb@hotmail.co.uk                 hotmail.co.uk\n",
       "2            info@hallsofhazlemere.com          hallsofhazlemere.com\n",
       "3                     kate@copas.co.uk                   copas.co.uk\n",
       "4            martinrowland30@gmail.com                     gmail.com\n",
       "5                 simon@cakesmiths.com                cakesmiths.com\n",
       "6            justin@ravenexpress.co.uk            ravenexpress.co.uk\n",
       "7            adam.thomas@greencore.com                 greencore.com\n",
       "8            allstarprov@optonline.net                 optonline.net\n",
       "9        gill.lyth@stuartandswan.co.uk           stuartandswan.co.uk"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the domain part of each email address:\n",
    "df['Email Domain'] = df['Email'].str.split('@').str[-1]\n",
    "# .str.split('@') splits each email string into two parts: local name and domain.\n",
    "# .str[-1] selects the last part (domain) after the split.\n",
    "\n",
    "# Inspecting the first 10 extracted domains to check the formatting:\n",
    "df[['Email', 'Email Domain']].head(10)\n",
    "# .head(10) displays the first 10 rows for verification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d34a61c",
   "metadata": {},
   "source": [
    "After standardising the email formatting, the next step is to extract the domain portion of each email address. The domain identifies the organisation or email provider used by the contact. This information is essential for several analysis options, including:\n",
    "- distinguishing corporate vs personal email addresses\n",
    "- inferring company information where website URLs are missing\n",
    "- identifying geographic indicators from top-level domains (example: .co.uk, .ie, .de)\n",
    "- grouping contacts by organisation for segmentation purposes\n",
    "\n",
    "To extract the domain, each email string is split at the \"@\" character and the final element of the resulting list is selected. This method works for all valid email addresses and preserves missing values (NaN).\n",
    "\n",
    "**ðŸ“š References:**<br>\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html\n",
    "- https://stackoverflow.com/questions/53044548/how-to-extract-domain-from-email-address-with-pandas\n",
    "- https://www.geeksforgeeks.org/python/split-a-column-in-pandas-dataframe-and-get-part-of-it/\n",
    "- https://www.geeksforgeeks.org/pandas/python-pandas-split-strings-into-two-list-columns-using-str-split/\n",
    "- https://medium.com/@amit25173/understanding-pandas-str-split-with-simple-examples-0bd7d12f4b4e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a031ca",
   "metadata": {},
   "source": [
    "### ...and exporting them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ee10ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_domains = df['Email Domain'].dropna().unique()\n",
    "# .dropna() removes missing values.\n",
    "# .unique() returns the set of unique domain names.\n",
    "\n",
    "domain_df = pd.DataFrame(unique_domains, columns=['Email Domain'])\n",
    "# Creates a new DataFrame to make exporting cleaner.\n",
    "\n",
    "domain_df.to_csv(\"data/cleaned/email_domains.csv\", index=False)\n",
    "# Exports the list of domains to a new CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffae56f",
   "metadata": {},
   "source": [
    "Exporting a list of all unique email domains is a convenient way to manually inspect the variety of domains present in the dataset. It can help with:<br>\n",
    "- identifying personal email providers\n",
    "- reviewing corporate domains\n",
    "- checking keyword-based industry inference\n",
    "\n",
    "**ðŸ“š References:**<br>\n",
    "- https://realpython.com/how-to-drop-null-values-in-pandas/\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.unique.html\n",
    "- https://www.w3schools.com/python/pandas/ref_df_dropna.asp\n",
    "- https://www.geeksforgeeks.org/python/python-pandas-dataframe-dropna/\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f028d1",
   "metadata": {},
   "source": [
    "### Adding missing country from UK & IE domains (target markets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b68a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For missing Country/Region values, checking if the email domain ends with .co.uk or .uk or .ie.\n",
    "# .str.endswith() checks if a string column ends with a specific substring.\n",
    "\n",
    "df.loc[\n",
    "    df['Country/Region'].isna() & df['Email Domain'].str.endswith('.co.uk', na=False),\n",
    "    'Country/Region'\n",
    "] = 'United Kingdom'\n",
    "\n",
    "df.loc[\n",
    "    df['Country/Region'].isna() & df['Email Domain'].str.endswith('.uk', na=False),\n",
    "    'Country/Region'\n",
    "] = 'United Kingdom'\n",
    "\n",
    "df.loc[\n",
    "    df['Country/Region'].isna() & df['Email Domain'].str.endswith('.ie', na=False),\n",
    "    'Country/Region'\n",
    "] = 'Ireland'\n",
    "\n",
    "# UK and Ireland are target markets for this dataset, so inference is limited to these domains only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7c9031",
   "metadata": {},
   "source": [
    "The Country/Region column contains many missing values. Because our target markets are the UK and Ireland, we can partially improve this field by checking whether an email domain ends with a country-specific domain (such as .ie or co.uk).\n",
    "\n",
    "**ðŸ“š References:**<br>\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.Series.str.endswith.html\n",
    "- https://stackoverflow.com/questions/67843895/python-loc-confusion-help-using-str-endswith\n",
    "- https://stackoverflow.com/questions/78382398/how-to-add-a-column-on-a-pandas-dataframe-that-is-based-on-the-continent-a-count\n",
    "- https://www.geeksforgeeks.org/python/python-pandas-dataframe-loc/\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html\n",
    "- https://www.geeksforgeeks.org/python/python-pandas-dataframe-isna/\n",
    "- https://www.ionos.com/digitalguide/websites/web-development/python-pandas-dataframe-isna/\n",
    "- https://python.plainenglish.io/how-to-prevent-pandas-from-interpreting-na-string-as-nan-00202f000a7d\n",
    "- https://stackoverflow.com/questions/28311655/ignoring-nans-with-str-contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ebfb9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if worked:\n",
    "df.to_csv(\"data/cleaned/country_draft_all.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
